version: '3.8'

networks:
  cdc-s3-sink:
    name: cdc-s3-sink
    driver: bridge

services:
  mysql:
    container_name: mysql
    image: mysql:8.1.0
    ports:
      - 3306:3306
    networks:
      - cdc-s3-sink
    environment:
      MYSQL_ROOT_PASSWORD: mysql123

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.5.0
    ports:
      - 2181:2181
    networks:
      - cdc-s3-sink
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - 9092:9092
    networks:
      - cdc-s3-sink
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka_connect_source:
    container_name: kafka_connect_source
    image: quay.io/debezium/connect:2.3
    ports:
      - 8083:8083
    networks:
      - cdc-s3-sink
    depends_on:
      - kafka
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_source_configs
      OFFSET_STORAGE_TOPIC: connect_source_offsets
      STATUS_STORAGE_TOPIC: connect_source_statuses
    command:
      - bash
      - -c
      - |
        echo "Launching Kafka Connect worker"
        /docker-entrypoint.sh start & 

        echo "Waiting for Kafka Connect to start listening on localhost:8083 ⏳"
        while : ; do
            curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
            echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
            if [ $$curl_status -eq 200 ] ; then
            break
            fi
            sleep 5
        done

        sleep 25

        echo -e "\n--\n+> Creating Kafka Connect source connectors"
        curl -i -X POST -H "Accept:application/json" \
          -H "Content-Type:application/json" \
          localhost:8083/connectors/ \
          -d '{
            "name": "mysqlconnector",
            "config": {
                "connector.class": "io.debezium.connector.mysql.MySqlConnector",
                "tasks.max": "1",
                "database.hostname": "mysql",
                "database.port": "3306",
                "database.user": "root",
                "database.password": "mysql123",
                "database.server.id": "184054",
                "topic.prefix": "mysqlconnector",
                "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
                "schema.history.internal.kafka.topic": "schemahistory.mysqlconnector",
                "include.schema.changes": "true"
            }
          }'
        
        sleep infinity

  kafka_connect_sink:
    container_name: kafka_connect_sink
    image: confluentinc/cp-kafka-connect:7.5.0
    ports:
      - 8084:8083
    networks:
      - cdc-s3-sink
    depends_on:
      - kafka
    env_file:
      - .env
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_GROUP_ID: 2
      CONNECT_CONFIG_STORAGE_TOPIC: connect_sink_configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect_sink_offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect_sink_statuses
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: localhost
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components
      CONNECT_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
    command:
      - bash
      - -c
      - |
        echo -e "\n Installing Connector"
        confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.5.0
        
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &

        echo "Waiting for Kafka Connect to start listening on localhost:8083 ⏳"
        while : ; do
            curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
            echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
            if [ $$curl_status -eq 200 ] ; then
            break
            fi
            sleep 5
        done

        echo -e "\n--\n+> Creating Kafka Connect sink connectors"
        curl -i -X PUT -H  "Content-Type:application/json" \
          http://localhost:8083/connectors/s3connector/config \
          -d '{
            "connector.class": "io.confluent.connect.s3.S3SinkConnector",
            "tasks.max": "1",
            "topics.regex": "mysqlconnector.*",
            "s3.region": "us-east-1",
            "s3.bucket.name": "cdc-s3-sink",
            "flush.size": "1",
            "storage.class": "io.confluent.connect.s3.storage.S3Storage",
            "format.class": "io.confluent.connect.s3.format.parquet.ParquetFormat",
            "schema.generator.class": "io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator",
            "partitioner.class": "io.confluent.connect.storage.partitioner.DefaultPartitioner",
            "name": "s3connector"
          }'
        
        sleep infinity
